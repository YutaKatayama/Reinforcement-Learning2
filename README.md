# Reinforcement-Learning2
強化学習の課題用レポジトリです。

### コードの説明


1. **Nomal.java**  
**役割**  
QLearningAsToMazeを単純に実行し、指定された迷路データを使って結果を出力するプログラム。引数として迷路ファイル、開始位置、終了位置、最大ステップ数、Q学習のパラメータを受け取る。  

**実行コマンド**  
```bash
# 具体例:
java Nomal <迷路ファイル> <開始位置> <終了位置> <最大ステップ数> <ε> <α> <γ>
```

**使い分け**  
単一の実行を行いたい場合や、特定のパラメータでの結果を確認したいときに使用する。

---

2. **RepeatedRunning.java**  
**役割**  
指定された回数だけQLearningAsToMazeを実行し、各実行の結果（学習回数やステップ数）を収集してCSVファイルに出力する。並列処理を使用して複数の実行を同時に行うことができる。  

**実行コマンド**  
```bash
# 実行例:
java RepeatedRunning
```

**実行時の入力**  
プログラム実行後、以下のパラメータをコンソールから入力する：  
- εの値  
- αの値  
- γの値  
- 実行回数  

**使い分け**  
複数回の実行を行い、結果を比較したい場合や、パラメータの影響を調査したいときに使用する。

---

3. **AutomaticParameterTuning.java**  
**役割**  
Q学習のハイパーパラメータ（ε, α, γ）を自動的に調整し、指定された範囲内で実行する。各パラメータの組み合わせでの実行結果を収集し、分散などの統計情報を出力する。  

**実行コマンド**  
```bash
# 実行例:
java AutomaticParameterTuning
```

**実行時の入力**  
プログラム実行後、以下のパラメータをコンソールから入力する：  
- εの初期値、終了値、増加幅  
- αの初期値、終了値、増加幅  
- γの初期値、終了値、増加幅  
- 実行回数  

**使い分け**  
ハイパーパラメータの最適化を行いたい場合や、異なるパラメータの組み合わせによる結果を比較したいときに使用する。  
